{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied tweets classification with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Label</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>304271250237304833</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'#SecKerry: The value of the @StateDept and @U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>304834304222064640</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'@rraina1481 I fear so'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>303568995880144898</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'Watch video highlights of the #wwc13 final be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>304366580664528896</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'RT @chelscanlan: At Nitro Circus at #AlbertPa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>296770931098009601</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'@cricketfox Always a good thing. Thanks for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>306713195832307712</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'Dr. Rajan: Fiscal consolidation will create m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>306100962337112064</td>\n",
       "      <td>Politics</td>\n",
       "      <td>FACT: More than 800,000 defense employees will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>305951758759366657</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'1st Test. Over 39: 0 runs, 1 wkt (M Wade 0, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>304482567158104065</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Some of Africa's top teams will try and take a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>303806584964935680</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'Can you beat the tweet of @RoryGribbell and z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetId     Label  \\\n",
       "0  304271250237304833  Politics   \n",
       "1  304834304222064640  Politics   \n",
       "2  303568995880144898    Sports   \n",
       "3  304366580664528896    Sports   \n",
       "4  296770931098009601    Sports   \n",
       "5  306713195832307712  Politics   \n",
       "6  306100962337112064  Politics   \n",
       "7  305951758759366657    Sports   \n",
       "8  304482567158104065    Sports   \n",
       "9  303806584964935680    Sports   \n",
       "\n",
       "                                           TweetText  \n",
       "0  '#SecKerry: The value of the @StateDept and @U...  \n",
       "1                            '@rraina1481 I fear so'  \n",
       "2  'Watch video highlights of the #wwc13 final be...  \n",
       "3  'RT @chelscanlan: At Nitro Circus at #AlbertPa...  \n",
       "4  '@cricketfox Always a good thing. Thanks for t...  \n",
       "5  'Dr. Rajan: Fiscal consolidation will create m...  \n",
       "6  FACT: More than 800,000 defense employees will...  \n",
       "7  '1st Test. Over 39: 0 runs, 1 wkt (M Wade 0, M...  \n",
       "8  Some of Africa's top teams will try and take a...  \n",
       "9  'Can you beat the tweet of @RoryGribbell and z...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "# Read the the training data \n",
    "df=pd.read_csv('C:/Users/TOCHIBA/desktop/train.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6525, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating for missing data in Label column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: Label, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data=df['Label'].isnull()\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    6525\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(missing_data.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we are sure that there is no missing value in our target column ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of simplicity I am going to classify our data as Politics or not Politics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Label</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>304271250237304833</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'#SecKerry: The value of the @StateDept and @U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>304834304222064640</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'@rraina1481 I fear so'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>303568995880144898</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'Watch video highlights of the #wwc13 final be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>304366580664528896</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'RT @chelscanlan: At Nitro Circus at #AlbertPa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>296770931098009601</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'@cricketfox Always a good thing. Thanks for t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>306713195832307712</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'Dr. Rajan: Fiscal consolidation will create m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>306100962337112064</td>\n",
       "      <td>Politics</td>\n",
       "      <td>FACT: More than 800,000 defense employees will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>305951758759366657</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'1st Test. Over 39: 0 runs, 1 wkt (M Wade 0, M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>304482567158104065</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Some of Africa's top teams will try and take a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>303806584964935680</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'Can you beat the tweet of @RoryGribbell and z...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetId     Label  \\\n",
       "0  304271250237304833  Politics   \n",
       "1  304834304222064640  Politics   \n",
       "2  303568995880144898    Sports   \n",
       "3  304366580664528896    Sports   \n",
       "4  296770931098009601    Sports   \n",
       "5  306713195832307712  Politics   \n",
       "6  306100962337112064  Politics   \n",
       "7  305951758759366657    Sports   \n",
       "8  304482567158104065    Sports   \n",
       "9  303806584964935680    Sports   \n",
       "\n",
       "                                           TweetText  target  \n",
       "0  '#SecKerry: The value of the @StateDept and @U...       1  \n",
       "1                            '@rraina1481 I fear so'       1  \n",
       "2  'Watch video highlights of the #wwc13 final be...       0  \n",
       "3  'RT @chelscanlan: At Nitro Circus at #AlbertPa...       0  \n",
       "4  '@cricketfox Always a good thing. Thanks for t...       0  \n",
       "5  'Dr. Rajan: Fiscal consolidation will create m...       1  \n",
       "6  FACT: More than 800,000 defense employees will...       1  \n",
       "7  '1st Test. Over 39: 0 runs, 1 wkt (M Wade 0, M...       0  \n",
       "8  Some of Africa's top teams will try and take a...       0  \n",
       "9  'Can you beat the tweet of @RoryGribbell and z...       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target']= np.where(df['Label']=='Politics',1,0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4904214559386973"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that most tweets in our dataset are not Politics which mean they are about sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TweetText'], \n",
    "                                                    df['target'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry:\n",
      "\n",
      " 'President Obama Calls for Humility at the National Prayer Breakfast http://t.co/3jlQQmPx'\n",
      "\n",
      "\n",
      "X_train shape:  (4893,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at X_train, we can see we have a series of over 4893 tweets or documents. We'll need to convert these into a numeric representation that scikit-learn can use. The bag-of-words approach is simple and commonly used way to represent text for use in machine learning, which ignores structure and only counts how often each word occurs. CountVectorizer allows us to use the bag-of-words approach by converting a collection of text documents into a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '177',\n",
       " '24mo',\n",
       " '477',\n",
       " '6urb8kla',\n",
       " 'aarava_on_ps3',\n",
       " 'afaqsworld',\n",
       " 'amenable',\n",
       " 'arians',\n",
       " 'avenue',\n",
       " 'bbge09su',\n",
       " 'bjp',\n",
       " 'brewing',\n",
       " 'calangute',\n",
       " 'cfsm8p9kcu',\n",
       " 'class',\n",
       " 'composed',\n",
       " 'county',\n",
       " 'd18mtttv',\n",
       " 'delivered',\n",
       " 'displaying',\n",
       " 'dubai',\n",
       " 'eliminate',\n",
       " 'est',\n",
       " 'fabwmyt0',\n",
       " 'financl',\n",
       " 'fourth',\n",
       " 'gen',\n",
       " 'grandson',\n",
       " 'happe',\n",
       " 'hlvoeg',\n",
       " 'hydroelectric',\n",
       " 'induced',\n",
       " 'islamist',\n",
       " 'johnsuncricket',\n",
       " 'khandm',\n",
       " 'lamb',\n",
       " 'lined',\n",
       " 'madrid',\n",
       " 'mcchrystal',\n",
       " 'min',\n",
       " 'muller',\n",
       " 'next',\n",
       " 'nytimes',\n",
       " 'ophz1f97kt',\n",
       " 'part',\n",
       " 'pilots',\n",
       " 'prague',\n",
       " 'proud2bs',\n",
       " 'qzlj4fnt',\n",
       " 'recorded',\n",
       " 'respect',\n",
       " 'ronthedon08',\n",
       " 'santa',\n",
       " 'sendblueroohome',\n",
       " 'sides',\n",
       " 'sometime',\n",
       " 'statedept',\n",
       " 'summer',\n",
       " 'tayyip',\n",
       " 'three',\n",
       " 'transfer',\n",
       " 'u2018heroic',\n",
       " 'until',\n",
       " 'vhfu1nz3re',\n",
       " 'warmongers',\n",
       " 'winter',\n",
       " 'xn1vrumsvs',\n",
       " 'zgc4fy6i']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at every 200th feature, we can get a small sense of what the vocabulary looks like. We can see it looks pretty messy, including words with numbers as well as misspellings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the transform method to transform the documents in X_train to a document term matrix, giving us the bag-of-word representation of X_train.This representation is stored in a SciPy sparse matrix, where each row corresponds to a document and each column a word from our training vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4893x13656 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 79440 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13656"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll start building our model which is the Logistic Regression model . The good thing about the logistic regression model is it is  very efficient  for binanry classification because it provides the probablity for each predicted label,also it works well for high dimensional sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TOCHIBA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9437280028674396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['atp' 'cfc' 'gt' 'indvaus' 'cricket' 'bbl02' 'f1' 'gbfedcup' 'ausgp'\n",
      " 'game']\n",
      "\n",
      "Largest Coefs: \n",
      "['nelsonmandela' 'pm' 'obama' 'medvedev' 'president' 'minister' 'meeting'\n",
      " 'seckerry' 'bcim2013' 'thank']\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start notice that the vocabulary now is much more significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at a different approach, which allows us to rescale features called tf–idf,Tf–idf, or Term frequency-inverse document frequency, allows us to weight terms based on how important they are to a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9231604486097286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TOCHIBA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['oldham' 'efc' '1st' 'tags' 'table' 'ble' 'emily' 'schmidt' 'suga' 'gone']\n",
      "\n",
      "Largest tfidf: \n",
      "['agree' 'love' 'enjoy' 'astonvilla' 'no' 'embracetherace' 'nice'\n",
      " 'challenge' 'ff' 'check']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['atp' 'cfc' 'indvaus' 'bbl02' 'gt' 'game' 'tennis' 'cricket' 'test' 'f1']\n",
      "\n",
      "Largest Coefs: \n",
      "['nelsonmandela' 'president' 'pm' 'obama' 'medvedev' 'of' 'minister'\n",
      " 'people' 'meeting' 'eu']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate our model using the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>306486520121012224</td>\n",
       "      <td>'28. The home side threaten again through Maso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>286353402605228032</td>\n",
       "      <td>'@mrbrown @aulia Thx for asking. See http://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>289531046037438464</td>\n",
       "      <td>'@Sochi2014 construction along the shores of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>306451661403062273</td>\n",
       "      <td>'#SecKerry\\u2019s remarks after meeting with F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>297941800658812928</td>\n",
       "      <td>'The #IPLauction has begun. Ricky Ponting is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>305722428531802112</td>\n",
       "      <td>'Viswanathan Anand draws with Fabiano Caruana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>304713516256997377</td>\n",
       "      <td>Have your say on tonight's game - send a text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>234999630725783553</td>\n",
       "      <td>'The #olympics may be over, but the #paralympi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>303712268372283392</td>\n",
       "      <td>'@richaanirudh big compliment, thanks!'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>304215754130194432</td>\n",
       "      <td>'Espargar\\xf3 @PolEspargaro quickest as Jerez ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetId                                          TweetText\n",
       "0  306486520121012224  '28. The home side threaten again through Maso...\n",
       "1  286353402605228032  '@mrbrown @aulia Thx for asking. See http://t....\n",
       "2  289531046037438464  '@Sochi2014 construction along the shores of t...\n",
       "3  306451661403062273  '#SecKerry\\u2019s remarks after meeting with F...\n",
       "4  297941800658812928  'The #IPLauction has begun. Ricky Ponting is t...\n",
       "5  305722428531802112  'Viswanathan Anand draws with Fabiano Caruana ...\n",
       "6  304713516256997377  Have your say on tonight's game - send a text ...\n",
       "7  234999630725783553  'The #olympics may be over, but the #paralympi...\n",
       "8  303712268372283392            '@richaanirudh big compliment, thanks!'\n",
       "9  304215754130194432  'Espargar\\xf3 @PolEspargaro quickest as Jerez ..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read the test data from my local computer\n",
    "df1=pd.read_csv('C:/Users/TOCHIBA/desktop/test.csv')\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2610, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test first entry:\n",
      "\n",
      " '28. The home side threaten again through Mason Bennett after he gets on the end of a long, long throw and stabs a yard wide.'\n"
     ]
    }
   ],
   "source": [
    "x_test=df1['TweetText']\n",
    "print('x_test first entry:\\n\\n', x_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the transformed test documents\n",
    "yhat = model.predict(vect.transform(x_test))\n",
    "\n",
    "yhat[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
